
Definition:
A thread is the smallest unit of execution within a process. It is often referred to as a "lightweight process" because it 
shares the resources (memory, open files, etc.) of its parent process, yet it can run concurrently with other threads.

-------------------------------------------------- Key Characteristics --------------------------------------------------

- Multiple threads can exist within a single process.
- Threads share the process's resources such as memory and file handles.
- Each thread has its own stack, register set, and program counter.
- Threads can run concurrently on multiple CPUs/cores, enhancing performance.
- Context switching between threads is typically faster than between processes.

----------------------------------------------- Comparison: Thread vs Process -------------------------------------------

- Process: Independent execution unit with its own memory space.
- Thread: Shares the memory space of the process but has its own execution context.

------------------------------------------------ Operations on Threads: -------------------------------------------------

1. Creation:
    - Threads are created using thread constructors (in languages like Java: using Thread class or Runnable interface).
    - The start() method is typically used to begin thread execution (e.g., thread.start() in Java).

2. Execution:
    - The run() method contains the code that will be executed by the thread.
    - Threads run concurrently, and their scheduling is determined by the operating system.

3. Synchronization:
    - To avoid race conditions, threads often require synchronization mechanisms.
    - Common methods include locks, semaphores, mutexes, and monitors.
    - Critical sections of code are protected to ensure only one thread executes them at a time.

4. Termination:
    - Threads can terminate normally by completing their run() method.
    - They can also be terminated forcefully in some environments, though it's generally avoided due to potential resource leaks.

------------------------------------------------ Thread States: -------------------------------------------------------

1. New: The thread is created but not yet started.
2. Runnable: The thread is ready to run and waiting for CPU time.
3. Running: The thread is currently executing.
4. Blocked/Waiting: The thread is waiting for a monitor lock or other resource.
5. Timed Waiting: The thread is waiting for a specified period.
6. Terminated: The thread has finished execution.

----------------------------------------------- Real-world Applications: -----------------------------------------------

1. Web Servers: Threads handle multiple client requests concurrently.
2. GUI Applications: Separate threads keep the user interface responsive while processing background tasks.
3. Database Servers: Threads manage multiple queries and transactions concurrently.
4. Parallel Processing: Multithreading allows concurrent data processing to enhance performance.
5. Network Programming: Threads handle simultaneous network operations, such as file transfers.

----------------------------------------------- Concurrency and Challenges: ---------------------------------------------

- Concurrency: Multiple threads can run concurrently to improve application performance and responsiveness.
- Synchronization Issues: Without proper synchronization, shared data may become inconsistent.
- Deadlocks: Occur when two or more threads are waiting indefinitely for resources held by each other.
- Starvation: Happens when a thread never gets CPU time to progress due to other threads monopolizing execution.
- Race Conditions: Occur when multiple threads access and modify shared data concurrently without proper synchronization, leading to unpredictable and erroneous behavior.

----------------------------------------------- Thread Implementation Examples (Java): -------------------------------------

Example: Creating a thread by extending the Thread class

    public class MyThread extends Thread {
         public void run() {
              System.out.println("Thread is running.");
         }
         public static void main(String args[]) {
              MyThread t = new MyThread();
              t.start();  // Start the thread
         }
    }

Example: Creating a thread using the Runnable interface

    public class MyRunnable implements Runnable {
         public void run() {
              System.out.println("Runnable thread is running.");
         }
         public static void main(String args[]) {
              Thread t = new Thread(new MyRunnable());
              t.start();  // Start the thread
         }
    }

---------------------------------------------------- Summary: ----------------------------------------------------------

- Threads provide a mechanism for concurrent execution within a process.
- They share resources with other threads within the same process but maintain separate execution contexts.
- Effective synchronization is crucial to avoid issues like race conditions and deadlocks.
- Programming with threads can lead to significant performance gains, especially on multi-core systems, when done correctly.


------------------------------------------------------ Concurrency vs. Parallelism ----------------------------------------

1. Definitions:
    - Concurrency:
      * Concurrency is the ability of a system to manage several tasks at once.
      * It involves interleaving execution steps (i.e., context switching) to give the appearance that tasks are running simultaneously, even on a single-core processor.
      * It is more about dealing with lots of things at once and is important for improving the responsiveness of an application.

    - Parallelism:
      * Parallelism is the literal simultaneous execution of tasks.
      * It requires hardware support, such as multi-core processors, where multiple tasks are executed simultaneously.
      * It is about doing lots of things at the same time and is used to increase computational speed and throughput.

-------------------------------------------------------------------------------------
2. Core Differences:
    - Execution:
      * Concurrency: Tasks are interleaved; they may not actually run at the same time but are managed in a way that maximizes resource utilization.
      * Parallelism: Tasks run at exactly the same time on separate cores or processors.
    
    - Resource Requirements:
      * Concurrency: Can be achieved on a single-core processor using time-slicing.
      * Parallelism: Requires multiple cores/CPUs to truly execute multiple instructions simultaneously.

    - Goals:
      * Concurrency: Often focuses on structuring a program to handle many tasks efficiently (e.g., managing I/O operations, user input, etc.).
      * Parallelism: Focuses on speeding up computation by dividing tasks into subtasks that can be processed concurrently.

-------------------------------------------------------------------------------------
4. Detailed Examples:

    Example of Concurrency:
    - Suppose you have two tasks: reading a file and processing user input.
    - On a single-core processor, an operating system (or a runtime like in Java) can switch between these tasks frequently.
    - Even though both tasks are not running at the same moment, they progress concurrently giving the appearance of simultaneous execution.

    Example in Java (Concurrent Execution using Threads):

         public class ConcurrencyExample extends Thread {
              public void run() {
                    for (int i = 0; i < 5; i++) {
                         System.out.println("Task: " + Thread.currentThread().getName() + " - " + i);
                         try {
                              // Simulates some work with a delay
                              Thread.sleep(100);
                         } catch (InterruptedException e) {
                              System.out.println("Thread interrupted");
                         }
                    }
              }
              public static void main(String[] args) {
                    ConcurrencyExample t1 = new ConcurrencyExample();
                    ConcurrencyExample t2 = new ConcurrencyExample();
                    t1.setName("Reader Task");
                    t2.setName("Input Processor Task");
                    t1.start();
                    t2.start();
              }
         }

    Explanation:
    - Both tasks (threads) are managed concurrently. On a single-core machine, they take turns executing based on time slicing.
    - They do not run exactly at the same time, but context switching allows both operations to make progress.

    Example of Parallelism:
    - Suppose a complex calculation needs to be divided into parts.
    - On a multicore processor, each core can handle a piece of the calculation simultaneously.

    Example in Java (Parallel Execution using Fork/Join Framework):

         import java.util.concurrent.RecursiveTask;
         import java.util.concurrent.ForkJoinPool;

         public class ParallelSum extends RecursiveTask<Long> {
              private final long[] numbers;
              private final int start, end;
              private static final int THRESHOLD = 10000;

              public ParallelSum(long[] numbers, int start, int end) {
                    this.numbers = numbers;
                    this.start = start;
                    this.end = end;
              }

              @Override
              protected Long compute() {
                    if (end - start < THRESHOLD) {
                         long sum = 0;
                         for (int i = start; i < end; i++) {
                              sum += numbers[i];
                         }
                         return sum;
                    } else {
                         int mid = (start + end) / 2;
                         ParallelSum leftTask = new ParallelSum(numbers, start, mid);
                         ParallelSum rightTask = new ParallelSum(numbers, mid, end);
                         leftTask.fork(); // execute in parallel
                         long rightResult = rightTask.compute();
                         long leftResult = leftTask.join();
                         return leftResult + rightResult;
                    }
              }

              public static void main(String[] args) {
                    int size = 1000000;
                    long[] numbers = new long[size];
                    for (int i = 0; i < size; i++) {
                         numbers[i] = i;
                    }
                    ForkJoinPool pool = new ForkJoinPool();
                    ParallelSum task = new ParallelSum(numbers, 0, numbers.length);
                    long sum = pool.invoke(task);
                    System.out.println("Total sum: " + sum);
              }
         }

    Explanation:
    - The Fork/Join framework breaks the problem into smaller sub-problems.
    - On a multicore processor, separate cores can compute parts of the problem in parallel.
    - It demonstrates parallelism since multiple cores process different segments of the array at the same time.

-------------------------------------------------------------------------------------
5. Summary:
    - Concurrency is a design pattern to handle multiple tasks by interleaving their execution and improving throughput and responsiveness, even on a single-core machine.
    - Parallelism is used to divide a task into parts that can be executed simultaneously for speeding up computation, which requires multiple processing units.
    - Both are important for modern software applications, but they solve different problems in computing.

These detailed notes should help clarify the conceptual and practical differences between concurrency and parallelism, along with real-world examples.